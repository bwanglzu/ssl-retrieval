# SSL CBIR Benchmark (WIP)

Benchmarking Self-supervised learning methods for content-based image retrieval.

## Datasets

[GLDV2](https://github.com/cvdfoundation/google-landmark): This is the second version of the Google Landmarks dataset (GLDv2), which contains images annotated with labels representing human-made and natural landmarks. 

[Similarity Challenge dataset](https://arxiv.org/pdf/2106.09672.pdf): in image copy detection, providing a reference collection of 1 million images, a development set of 50,000 query images, and a test set of 50,000 additional query images.

## Models

baseline1: zero-shot efficientnet b0.

baseline2: fine-tuned efficientnet b0 (metric-learning).

[SimCLRV2](https://arxiv.org/abs/2006.10029): Big Self-Supervised Models are Strong Semi-Supervised Learners.

[MoCoV3](https://arxiv.org/abs/2104.02057): An Empirical Study of Training Self-Supervised Vision Transformers.

[DINO](https://arxiv.org/abs/2104.14294): Emerging Properties in Self-Supervised Vision Transformers.

[SimSiam](https://arxiv.org/abs/2011.10566): Exploring Simple Siamese Representation Learning.

[MAE](https://arxiv.org/abs/2111.06377): Masked Autoencoders Are Scalable Vision Learners.
